{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CPSC 330 Lecture 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lecture plan\n",
    "\n",
    "- 👋\n",
    "- **Turn on recording**\n",
    "- Announcements (5 min)\n",
    "- Evaluation metrics True/False (10 min)\n",
    "- Introducing some other classifiers (20 min)\n",
    "- Break (5 mins)\n",
    "- Ensembles: averaging (20 min)\n",
    "- Ensembles: stacking (20 min)\n",
    "- Summary\n",
    "\n",
    "Piazza:\n",
    "\n",
    "- Ensembles True/False questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announcements\n",
    "\n",
    "- hw schedule for the rest of the course posted at https://github.com/UBC-CS/cpsc330#homework-schedule\n",
    "- hw4 posted, due Monday 11:59pm\n",
    "- Evaluation metrics true/false: https://piazza.com/class/kb2e6nwu3uj23?cid=283\n",
    "- Midterm format: https://piazza.com/class/kb2e6nwu3uj23?cid=281 and https://piazza.com/class/kb2e6nwu3uj23?cid=284"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Name a few popular tree-based classifier.\n",
    "- Name a few key hyperparameters of random forest classifiers.\n",
    "- Weigh the pros and cons of using a classifier from outside scikit-learn.\n",
    "- Employ ensemble classifier approaches, in particular model averaging and stacking\n",
    "- Compare averaging vs. stacking\n",
    "- Interpret the coefficients of the meta-classifier in the case of stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from lecture 2\n",
    "import re\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def display_tree(feature_names, tree):\n",
    "    \"\"\" For binary classification only \"\"\"\n",
    "    dot = export_graphviz(tree, out_file=None, feature_names=feature_names, class_names=tree.classes_.astype(str), impurity=False)\n",
    "    # adapted from https://stackoverflow.com/questions/44821349/python-graphviz-remove-legend-on-nodes-of-decisiontreeclassifier\n",
    "    dot = re.sub('(\\\\\\\\nsamples = [0-9]+)(\\\\\\\\nvalue = \\[[0-9]+, [0-9]+\\])(\\\\\\\\nclass = [A-Za-z0-9]+)', '', dot)\n",
    "    dot = re.sub(     '(samples = [0-9]+)(\\\\\\\\nvalue = \\[[0-9]+, [0-9]+\\])\\\\\\\\n', '', dot)\n",
    "    return graphviz.Source(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing some other classifiers (20 min)\n",
    "\n",
    "- SVM?\n",
    "- Random forest\n",
    "- XGB, Catboost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv('data/creditcard.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today I will use a smaller data set for speed of the demos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = cc_df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(cc_df, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21360, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['Class'])\n",
    "y_train = df_train['Class']\n",
    "\n",
    "X_test = df_test.drop(columns=['Class'])\n",
    "y_test = df_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_method = 'average_precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.172929\n",
       "score_time     0.006745\n",
       "test_score     0.754187\n",
       "train_score    0.843295\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pd.DataFrame(cross_validate(pipe_lr, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(class_weight='balanced') # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.188989\n",
       "score_time     0.002935\n",
       "test_score     0.480743\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results = pd.DataFrame(cross_validate(dt, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about some other classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is basically the average of a bunch of random decision trees. \n",
    "- We'll talk about averaging later today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', random_state=999) # scaling not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       2.222700\n",
       "score_time     0.024789\n",
       "test_score     0.827076\n",
       "train_score    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results = pd.DataFrame(cross_validate(rf, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets a better score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.222700</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.827076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.172929</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.754187</td>\n",
       "      <td>0.843295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.188989</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.480743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  score_time  test_score  train_score\n",
       "random forest        2.222700    0.024789    0.827076     1.000000\n",
       "logistic regression  0.172929    0.006745    0.754187     0.843295\n",
       "decision tree        0.188989    0.002935    0.480743     1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([lr_results, dt_results, rf_results], index=[\"logistic regression\", \"decision tree\", \"random forest\"])\n",
    "summary.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are these random forests you speak of?\n",
    "\n",
    "- They are a collection of decision trees.\n",
    "- Each tree \"votes\" on the prediction, majority rules (more on this later).\n",
    "- Each tree (and split) is limited in the number of features it can look at.\n",
    "- Each tree is training on a slightly different version of the dataset. \n",
    "\n",
    "We can actually look at the sub-trees in a trained random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 1\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"380pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 380.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 376,-184 376,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"241,-180 131,-180 131,-144 241,-144 241,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"186\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V16 &lt;= &#45;3.959.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"177.5,-108 72.5,-108 72.5,-72 177.5,-72 177.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V21 &lt;= 0.225.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.6071,-143.8314C163.5096,-135.454 154.952,-125.3531 147.176,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.7348,-113.7807 140.6001,-108.4133 144.3939,-118.3056 149.7348,-113.7807\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.5395\" y=\"-129.6282\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"298.5,-108 195.5,-108 195.5,-72 298.5,-72 298.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V9 &lt;= &#45;3.695.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.3929,-143.8314C208.4904,-135.454 217.048,-125.3531 224.824,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"227.6061,-118.3056 231.3999,-108.4133 222.2652,-113.7807 227.6061,-118.3056\"/>\n",
       "<text text-anchor=\"middle\" x=\"233.4605\" y=\"-129.6282\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M103.0462,-71.8314C92.3305,-62.9632 79.2811,-52.1637 67.691,-42.5718\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.8822,-39.8422 59.9467,-36.1628 65.4192,-45.2349 69.8822,-39.8422\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.7664,-71.8314C127.515,-64.131 128.4053,-54.9743 129.2373,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.7256,-46.7051 130.2098,-36.4133 125.7585,-46.0276 132.7256,-46.7051\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"278,-36 202,-36 202,0 278,0 278,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245.2336,-71.8314C244.485,-64.131 243.5947,-54.9743 242.7627,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"246.2415,-46.0276 241.7902,-36.4133 239.2744,-46.7051 246.2415,-46.0276\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"372,-36 296,-36 296,0 372,0 372,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"334\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M268.9538,-71.8314C279.6695,-62.9632 292.7189,-52.1637 304.309,-42.5718\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"306.5808,-45.2349 312.0533,-36.1628 302.1178,-39.8422 306.5808,-45.2349\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa4dbda6280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 2\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"383pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 383.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 379,-184 379,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"242,-180 132,-180 132,-144 242,-144 242,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V16 &lt;= &#45;4.322.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"178,-108 68,-108 68,-72 178,-72 178,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V25 &lt;= &#45;2.937.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.8501,-143.8314C163.3283,-135.3694 154.2435,-125.1489 146.0196,-115.8971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"148.627,-113.5621 139.3673,-108.4133 143.3951,-118.2127 148.627,-113.5621\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.8993\" y=\"-129.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"306,-108 196,-108 196,-72 306,-72 306,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"251\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V16 &lt;= &#45;2.615.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M203.1499,-143.8314C210.6717,-135.3694 219.7565,-125.1489 227.9804,-115.8971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.6049,-118.2127 234.6327,-108.4133 225.373,-113.5621 230.6049,-118.2127\"/>\n",
       "<text text-anchor=\"middle\" x=\"236.1007\" y=\"-129.6701\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M101.5509,-71.8314C91.1822,-63.0485 78.5771,-52.3712 67.3354,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.3349,-39.9556 59.4422,-36.1628 64.8105,-45.297 69.3349,-39.9556\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M125.2711,-71.8314C126.2336,-64.131 127.3782,-54.9743 128.4479,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.9309,-46.7702 129.6983,-36.4133 124.9849,-45.9019 131.9309,-46.7702\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"281,-36 205,-36 205,0 281,0 281,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M248.9813,-71.8314C248.1257,-64.131 247.1083,-54.9743 246.1574,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"249.6289,-45.9656 245.0459,-36.4133 242.6717,-46.7386 249.6289,-45.9656\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"375,-36 299,-36 299,0 375,0 375,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"337\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M272.7014,-71.8314C283.1921,-63.0485 295.9455,-52.3712 307.3194,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.8847,-45.2659 315.3055,-36.1628 305.3911,-39.8986 309.8847,-45.2659\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa4dbda67c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tree 3\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"382pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 382.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 378,-184 378,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"239.5,-180 134.5,-180 134.5,-144 239.5,-144 239.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V11 &lt;= 3.707.0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"179,-108 69,-108 69,-72 179,-72 179,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"124\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V16 &lt;= &#45;4.451.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M171.1024,-143.8314C163.7722,-135.454 154.934,-125.3531 146.9031,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"149.3307,-113.6343 140.1116,-108.4133 144.0627,-118.2438 149.3307,-113.6343\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.4486\" y=\"-129.6579\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"302.5,-108 197.5,-108 197.5,-72 302.5,-72 302.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V15 &lt;= 1.862.0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M202.8976,-143.8314C210.2278,-135.454 219.066,-125.3531 227.0969,-116.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.9373,-118.2438 233.8884,-108.4133 224.6693,-113.6343 229.9373,-118.2438\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.5514\" y=\"-129.6579\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"76,-36 0,-36 0,0 76,0 76,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"38\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.2986,-71.8314C91.8079,-63.0485 79.0545,-52.3712 67.6806,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.6089,-39.8986 59.6945,-36.1628 65.1153,-45.2659 69.6089,-39.8986\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"170,-36 94,-36 94,0 170,0 170,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.0187,-71.8314C126.8743,-64.131 127.8917,-54.9743 128.8426,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"132.3283,-46.7386 129.9541,-36.4133 125.3711,-45.9656 132.3283,-46.7386\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"280,-36 204,-36 204,0 280,0 280,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247.9813,-71.8314C247.1257,-64.131 246.1083,-54.9743 245.1574,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.6289,-45.9656 244.0459,-36.4133 241.6717,-46.7386 248.6289,-45.9656\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"374,-36 298,-36 298,0 374,0 374,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0.0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271.7014,-71.8314C282.1921,-63.0485 294.9455,-52.3712 306.3194,-42.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.8847,-45.2659 314.3055,-36.1628 304.3911,-39.8986 308.8847,-45.2659\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa4dbda6640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_demo = RandomForestClassifier(max_depth=2, n_estimators=3)\n",
    "rf_demo.fit(X_train, y_train)\n",
    "for i, tree in enumerate(rf_demo.estimators_):\n",
    "    print(\"\\n\\nTree\", i+1)\n",
    "    display(display_tree(X_train.columns, tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they look at different features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notable hyperparameters:\n",
    "\n",
    "- `n_estimators`: number of decision trees (higher = more complexity)\n",
    "- `max_depth`: max depth of each decision tree (higher = more complexity)\n",
    "- `max_features`: the number of features you get to look at each split (higher = more complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also try some other tree-based classifiers from outside sklearn.\n",
    "- There are more \"fancy\" are are **extremely popular**.  \n",
    "- Over time, people created \"sklearn-friendly\" wrappers so that these classifiers are compatible with all that we know & love.\n",
    "  - As long as they implement `fit` and `predict` and `predict_proba` and `score` we can plug them right in.\n",
    "  - Important to note that all of these **do** implement `predict_proba` so we can use something like ROC AUC.\n",
    "  - The probability scores come from the variation in the votes across trees, and other fancier sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBClassifier` doesn't have an easy implementation of `class_weight='balanced'` AFAIK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    473.666667\n",
       "1      1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = y_train.value_counts()\n",
    "vc = vc/vc.iloc[1]\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'logistic regression' : pipe_lr,\n",
    "    'decision tree' : dt,\n",
    "    'random forest' : rf,\n",
    "    'XGBoost' : XGBClassifier(scale_pos_weight=500, random_state=999), \n",
    "    'LightGBM' : LGBMClassifier(class_weight='balanced', random_state=999),\n",
    "    'CatBoost' : CatBoostClassifier(auto_class_weights='Balanced', verbose=0, random_state=999)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "decision tree\n",
      "random forest\n",
      "XGBoost\n",
      "LightGBM\n",
      "CatBoost\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for name, classifier in classifiers.items():\n",
    "    print(name)\n",
    "    results[name] = pd.DataFrame(cross_validate(classifier, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.010176</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.999537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.198490</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.827076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.689208</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.815958</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.184093</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.754187</td>\n",
       "      <td>0.843295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.292502</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.203903</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.483880</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  score_time  test_score  train_score\n",
       "CatBoost             7.010176    0.005564    0.854836     0.999537\n",
       "random forest        2.198490    0.024167    0.827076     1.000000\n",
       "XGBoost              0.689208    0.006755    0.815958     1.000000\n",
       "logistic regression  0.184093    0.004813    0.754187     0.843295\n",
       "LightGBM             0.292502    0.010596    0.715381     1.000000\n",
       "decision tree        0.203903    0.003446    0.483880     1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results).T\n",
    "results.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My thoughts:\n",
    "\n",
    "- Keep in mind all of the above is with:\n",
    "  - Default hyperparameters (except `class_weight`)\n",
    "  - A particular scoring metric\n",
    "  - 5-fold CV\n",
    "- All the trees totally overfit\n",
    "  - We may do better by tweaking the hyperparameters\n",
    "- Look at the fit times! And the score times are also interesting.\n",
    "  - Is is typical that `predict`/`score` are much faster than `fit` (with one notable exception, coming later in the course)\n",
    "- Note that CatBoost took about 10x longer than XGBoost and the scores only differ by <1%\n",
    "  - We took the mean of the sub-scores, but we might want to look more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What classifier should I use?!\n",
    "\n",
    "- Cop out answer: whichever gets the highest CV score.\n",
    "  - But we shouldn't overuse the validation set.\n",
    "  - This seems more reasonable when you have more data.\n",
    "  - It's time-consuming.\n",
    "- You may also have a reason to choose one over another.\n",
    "- One reason is _interpretability_, which we'll talk a bit more about next week.\n",
    "  - This is an area of growing interest and concern in ML.\n",
    "- Other considerations could be speed (fit and/or predict), maintainability of the code.\n",
    "- Finally, you could use all of them! (That's what the rest of today is about!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break (5 min)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: averaging (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we looked at a bunch of classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic regression': Pipeline(steps=[('scale', StandardScaler()),\n",
       "                 ('lr',\n",
       "                  LogisticRegression(class_weight='balanced', max_iter=1000))]),\n",
       " 'decision tree': DecisionTreeClassifier(class_weight='balanced'),\n",
       " 'random forest': RandomForestClassifier(class_weight='balanced', random_state=999),\n",
       " 'XGBoost': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               random_state=999, reg_alpha=None, reg_lambda=None,\n",
       "               scale_pos_weight=500, subsample=None, tree_method=None,\n",
       "               validate_parameters=None, verbosity=None),\n",
       " 'LightGBM': LGBMClassifier(class_weight='balanced', random_state=999),\n",
       " 'CatBoost': <catboost.core.CatBoostClassifier at 0x7fa4dc1ce8b0>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we training a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model = VotingClassifier(list(classifiers.items()), voting='soft') # need the list() here for cross_val to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This `VotingClassifier` will take a _vote_ using the predictions of the constituent classifiers.\n",
    "  - Or, more generally, classifier pipelines!\n",
    "- Note the `voting='soft'`\n",
    "  - By default (`voting='hard'`) it uses the output of `predict` and actually votes.\n",
    "  - with `voting='soft'` it averages the output of `predict_proba` and then thresholds / takes the larger.\n",
    "  - The choice depends on whether you trust `predict_proba` from your base classifiers - if so, it's nice to access that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it seems sklearn requires us to actually call `fit` on the `VotingClassifier`, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaging_model.predict(X_test[100:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hard voting, these are the votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic regression': 0,\n",
       " 'decision tree': 0,\n",
       " 'random forest': 0,\n",
       " 'XGBoost': 0,\n",
       " 'LightGBM': 0,\n",
       " 'CatBoost': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = {name : classifier.predict(X_test[100:101])[0] for name, classifier in averaging_model.named_estimators_.items()}\n",
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For soft voting, these are the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.998161</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1\n",
       "logistic regression  0.998161  0.001839\n",
       "decision tree        1.000000  0.000000\n",
       "random forest        1.000000  0.000000\n",
       "XGBoost              0.999990  0.000010\n",
       "LightGBM             0.999978  0.000022\n",
       "CatBoost             0.999878  0.000122"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = {name : classifier.predict_proba(X_test[100:101])[0] for name, classifier in averaging_model.named_estimators_.items()}\n",
    "pd.DataFrame(r2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.999668\n",
       "1    0.000332\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(r2).T.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aside: the probability scores from `DecisionTreeClassifier` are pretty bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       11.440629\n",
       "score_time      0.073147\n",
       "test_score      0.823204\n",
       "train_score     1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vot_res = pd.DataFrame(cross_validate(averaging_model, X_train, y_train, scoring=score_method, return_train_score=True)).mean()\n",
    "vot_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>7.010176</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.999537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.198490</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.827076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>11.440629</td>\n",
       "      <td>0.073147</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.689208</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.815958</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.184093</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.754187</td>\n",
       "      <td>0.843295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.292502</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.203903</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.483880</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fit_time  score_time  test_score  train_score\n",
       "CatBoost              7.010176    0.005564    0.854836     0.999537\n",
       "random forest         2.198490    0.024167    0.827076     1.000000\n",
       "Voting               11.440629    0.073147    0.823204     1.000000\n",
       "XGBoost               0.689208    0.006755    0.815958     1.000000\n",
       "logistic regression   0.184093    0.004813    0.754187     0.843295\n",
       "LightGBM              0.292502    0.010596    0.715381     1.000000\n",
       "decision tree         0.203903    0.003446    0.483880     1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_avg = pd.concat((results, pd.DataFrame(vot_res, columns=[\"Voting\"]).T))\n",
    "results_with_avg.sort_values(by=[\"test_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we did a bit better than even our best classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Question: how could the average do better than the best model???\n",
    "  - From the perspective of the best estimator (in this case CatBoost), why are you adding on worse estimators??\n",
    "  \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how this can work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example | log reg    | rand for     | cat boost    | Averaged model |\n",
    "|--------|--------|--------|---------|---------------|\n",
    "|  1     | ✅    |   ✅    | ❌     | ✅✅❌=>✅  |\n",
    "|  2     | ✅    |   ❌    | ✅     | ✅❌✅=>✅  |\n",
    "|  3     | ❌    |   ✅    | ✅     | ❌✅✅=>✅  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, as long as the different models make different mistakes, this can work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is amazing, why not always do this?\n",
    "\n",
    "1. `fit`/`predict` time.\n",
    "2. Reduction in interpretability.\n",
    "3. Reduction in code maintainability (e.g. Netflix prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to ensembling: when can I do this?\n",
    "\n",
    "- You can comebine completely different estimators, or similar estimators.\n",
    "  - (In fact, a random forest itself is an ensemble of decision trees.)\n",
    "- But you can also try different hyperparameter values.\n",
    "  - So... the hyperparameters of the ensemble now go even deeper.\n",
    "  - The inception never ends... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles: stacking (20 min)\n",
    "\n",
    "- Another type of ensemble is stacking.\n",
    "- Instead of averaging the outputs of each estimator, instead use their outputs as _inputs to another model_.\n",
    "- By default for classification, it uses logistic regression.\n",
    "  - We don't need a complex model here necessarily, more of a weighted average.\n",
    "  - The features going into the logistic regression are the classifier outputs, _not_ the original features!\n",
    "  - So the number of coefficients = the number of base estimators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code starts to get too slow here; I'm going to remove CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_nocat = classifiers.copy()\n",
    "del classifiers_nocat[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingClassifier(list(classifiers_nocat.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on in here? \n",
    "\n",
    "- It is doing cross-validation by itself by default (see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html))\n",
    "  - It is fitting the base estimators on the training fold\n",
    "  - And the predicting on the validation fold\n",
    "  - And then fitting the meta-estimator on that output (on the validation fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict(X_test[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99535216e-01, 4.64784296e-04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.predict_proba(X_test[100:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This is the `predict_proba` from logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       15.867804\n",
       "score_time      0.048982\n",
       "test_score      0.818445\n",
       "train_score     1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(stacking_model, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The situation here is a bit mind-boggling.\n",
    "- AFAIK on each fold of cross-validation it is doing cross-validation.\n",
    "- And then in there you might have pipelines and...\n",
    "- This is really loops within loops within loops within loops..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the input features (X) to the meta-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.998161</td>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1\n",
       "logistic regression  0.998161  0.001839\n",
       "decision tree        1.000000  0.000000\n",
       "random forest        1.000000  0.000000\n",
       "XGBoost              0.999990  0.000010\n",
       "LightGBM             0.999978  0.000022"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3 = {name : classifier.predict_proba(X_test[100:101])[0] for name, classifier in stacking_model.named_estimators_.items()}\n",
    "r3 = pd.DataFrame(r3).T\n",
    "r3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Because this needs to work for multi-class now I'm not quite sure if both probabilities are going in or just one - I think just one - this is a bit simpler for regression!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the meta-model is logistic regression (which it is by default), you are taking a weighted average of these outputs and learning the weights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.09513413, 0.37568601, 2.74765815, 3.10055386, 1.73767135]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>3.095134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.375686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>2.747658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>3.100554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.737671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Coefficient\n",
       "logistic regression     3.095134\n",
       "decision tree           0.375686\n",
       "random forest           2.747658\n",
       "XGBoost                 3.100554\n",
       "LightGBM                1.737671"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=stacking_model.final_estimator_.coef_[0], index=classifiers_nocat.keys(), columns=[\"Coefficient\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems that the XGBoost is being trusted the most / counting for most.\n",
    "- We can also try a different final estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model_tree = StackingClassifier(list(classifiers_nocat.items()), \n",
    "                                        final_estimator=DecisionTreeClassifier(max_depth=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       16.298363\n",
       "score_time      0.050169\n",
       "test_score      0.667855\n",
       "train_score     0.944318\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(stacking_model_tree, X_train, y_train, scoring=score_method, return_train_score=True)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very good. But we can look at the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model_tree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"708pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 708.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 704,-256 704,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"427.5,-252 278.5,-252 278.5,-216 427.5,-216 427.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.185</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"344.5,-180 195.5,-180 195.5,-144 344.5,-144 344.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"270\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.065</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M332.0556,-215.8314C321.9309,-207.0485 309.6223,-196.3712 298.6452,-186.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"300.7851,-184.0718 290.9377,-180.1628 296.1981,-189.3595 300.7851,-184.0718\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.7074\" y=\"-201.4001\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"511.5,-180 362.5,-180 362.5,-144 511.5,-144 511.5,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"437\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.485</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374.1967,-215.8314C384.4434,-207.0485 396.9003,-196.3712 408.0097,-186.8489\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"410.4952,-189.3282 415.81,-180.1628 405.9397,-184.0134 410.4952,-189.3282\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.8926\" y=\"-201.3892\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"194.5,-108 21.5,-108 21.5,-72 194.5,-72 194.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"108\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">logistic regression &lt;= 0.999</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M229.1206,-143.8314C207.454,-134.2018 180.6637,-122.295 157.7922,-112.1299\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.1451,-108.9011 148.5855,-108.038 156.3021,-115.2978 159.1451,-108.9011\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"337,-108 213,-108 213,-72 337,-72 337,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"275\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">XGBoost &lt;= 0.713</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M271.2617,-143.8314C271.7965,-136.131 272.4323,-126.9743 273.0266,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"276.52,-118.6317 273.7213,-108.4133 269.5368,-118.1467 276.52,-118.6317\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"66,-36 0,-36 0,0 66,0 66,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"33\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.0743,-71.8314C80.0143,-63.1337 69.0191,-52.5783 59.1735,-43.1265\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5574,-40.5633 51.9196,-36.1628 56.7096,-45.613 61.5574,-40.5633\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"150,-36 84,-36 84,0 150,0 150,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M110.2711,-71.8314C111.2336,-64.131 112.3782,-54.9743 113.4479,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.9309,-46.7702 114.6983,-36.4133 109.9849,-45.9019 116.9309,-46.7702\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"260,-36 194,-36 194,0 260,0 260,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"227\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M262.8876,-71.8314C257.4719,-63.7079 250.9758,-53.9637 245.0079,-45.0118\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.7347,-42.7923 239.2755,-36.4133 241.9104,-46.6753 247.7347,-42.7923\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"344,-36 278,-36 278,0 344,0 344,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M284.0843,-71.8314C288.0615,-63.8771 292.8155,-54.369 297.2139,-45.5723\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"300.4517,-46.9228 301.7934,-36.4133 294.1907,-43.7923 300.4517,-46.9228\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"498.5,-108 365.5,-108 365.5,-72 498.5,-72 498.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"432\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LightGBM &lt;= 0.525</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M435.7383,-143.8314C435.2035,-136.131 434.5677,-126.9743 433.9734,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.4632,-118.1467 433.2787,-108.4133 430.48,-118.6317 437.4632,-118.1467\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"665.5,-108 516.5,-108 516.5,-72 665.5,-72 665.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"591\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random forest &lt;= 0.975</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M475.8607,-143.8314C496.2742,-134.2874 521.4723,-122.5065 543.086,-112.4013\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"544.8423,-115.4439 552.4187,-108.038 541.8775,-109.1027 544.8423,-115.4439\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"441,-36 375,-36 375,0 441,0 441,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"408\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M425.9438,-71.8314C423.3488,-64.0463 420.2576,-54.7729 417.3782,-46.1347\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"420.6205,-44.7933 414.1378,-36.4133 413.9797,-47.0069 420.6205,-44.7933\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"525,-36 459,-36 459,0 525,0 525,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"492\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M447.1405,-71.8314C454.1217,-63.454 462.5391,-53.3531 470.1876,-44.1749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"472.9425,-46.3362 476.6556,-36.4133 467.5649,-41.8548 472.9425,-46.3362\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"616,-36 550,-36 550,0 616,0 616,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"583\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M588.9813,-71.8314C588.1257,-64.131 587.1083,-54.9743 586.1574,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"589.6289,-45.9656 585.0459,-36.4133 582.6717,-46.7386 589.6289,-45.9656\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"700,-36 634,-36 634,0 700,0 700,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"667\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M610.178,-71.8314C619.3588,-63.1337 630.5006,-52.5783 640.4776,-43.1265\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"642.9757,-45.5811 647.8281,-36.1628 638.1615,-40.4995 642.9757,-45.5811\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fa4dc5b2070>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_tree(list(classifiers_nocat.keys()), stacking_model_tree.final_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so cool!! (Well,  think so)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An effective strategy\n",
    "\n",
    "- Randomly generate a bunch of models with different hyperparameter configurations, and then stack all the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "\n",
    "(Pause for Q&A)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "- There's a big world of classifiers out there.\n",
    "  - Tree-based classifiers are particularly popular and effective on a wide range of problems. \n",
    "  - These can be much more complex than LogisticRegression, which only learns one coefficient per feature.\n",
    "- We sometimes need to leave the world of scikit-learn (and more of that later in the course!).\n",
    "- Ensembles are usually pretty effective.\n",
    "  - But they trade off code complexity and code speed for prediction accuracy.\n",
    "  - Don't forget that hyperparameter optimization multiplies the slowness of the code!\n",
    "- Stacking is a bit slower than voting, but generally more accuracy.\n",
    "  - As a bonus, you get to see the coefficients for each base classifier.\n",
    "- Remember, everything we've done is subject to earlier warnings:\n",
    "  - Check for small datasets\n",
    "  - Check the CV folds\n",
    "  - Check the test set\n",
    "  - Think carefully about which scoring metric is suitable for your problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## True/False questions (Piazza)\n",
    "\n",
    "1. I can decide to average different models even _after_ I (or someone else) have already trained them.\n",
    "2. Let estimators A, B, and C have scores of 90%, 70%, and 70%, respectively. Then, the maximum score of an ensemble is 90%. \n",
    "3. Let estimators A, B, and C have scores of 70%, 70%, and 70%, respectively. Then, the minimum score of an ensemble is 70%.\n",
    "4. Ensembling often increase your score but they also increase the time spent fitting and predicting.\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
